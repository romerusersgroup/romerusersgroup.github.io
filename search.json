[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Us",
    "section": "",
    "text": "We are committed to providing high-quality, accessible, and engaging educational resources that empower learners of all ages. Our mission is to foster a love for learning and to support the development of critical thinking skills through innovative and interactive content."
  },
  {
    "objectID": "about.html#our-mission",
    "href": "about.html#our-mission",
    "title": "About Us",
    "section": "",
    "text": "We are committed to providing high-quality, accessible, and engaging educational resources that empower learners of all ages. Our mission is to foster a love for learning and to support the development of critical thinking skills through innovative and interactive content."
  },
  {
    "objectID": "about.html#who-we-are",
    "href": "about.html#who-we-are",
    "title": "About Us",
    "section": "Who We Are?",
    "text": "Who We Are?\nWe believe education has the power to transform lives. Our team is dedicated to making learning accessible, meaningful, and inspiring for everyone.\n\n\nOrganizers Sponsors"
  },
  {
    "objectID": "about/sponsors.html",
    "href": "about/sponsors.html",
    "title": "Sponsor",
    "section": "",
    "text": "We are thrilled to announce our latest partnership with R Consortium, a pivotal player in the world of data science and programming. R Consortium is a non-profit organization committed to advancing the R language and fostering innovation within the R community."
  },
  {
    "objectID": "about/sponsors.html#introducing-our-new-sponsor-r-consortium",
    "href": "about/sponsors.html#introducing-our-new-sponsor-r-consortium",
    "title": "Sponsor",
    "section": "",
    "text": "We are thrilled to announce our latest partnership with R Consortium, a pivotal player in the world of data science and programming. R Consortium is a non-profit organization committed to advancing the R language and fostering innovation within the R community."
  },
  {
    "objectID": "about/sponsors.html#why-r-consortium",
    "href": "about/sponsors.html#why-r-consortium",
    "title": "Sponsor",
    "section": "Why R Consortium?",
    "text": "Why R Consortium?\nR Consortium‚Äôs mission aligns perfectly with our goals at R-Ladies Rome. They provide essential support to projects and initiatives that enhance R‚Äôs capabilities and accessibility. By partnering with R Consortium, we‚Äôre strengthening our commitment to empowering data enthusiasts, promoting R programming, and fostering a vibrant community."
  },
  {
    "objectID": "about/sponsors.html#what-this-means-for-you",
    "href": "about/sponsors.html#what-this-means-for-you",
    "title": "Sponsor",
    "section": "What This Means for You",
    "text": "What This Means for You\nThis partnership brings numerous benefits to our community. We‚Äôll have access to valuable resources, expertise, and opportunities that will further enrich our events and activities. Together, we‚Äôll continue to grow, learn, and share knowledge within the R programming ecosystem.\nWe‚Äôre grateful for the support of R Consortium and look forward to the exciting opportunities this collaboration will bring. Stay tuned for upcoming events and initiatives that will showcase the incredible possibilities unlocked by this partnership.\nLet‚Äôs embark on this journey together, embracing the power of R programming and data science with R Consortium by our side. Here‚Äôs to a bright future of learning, innovation, and community-building!\n#RConsortium #RProgramming #DataScience #CommunityBuilding"
  },
  {
    "objectID": "content/events/index.html",
    "href": "content/events/index.html",
    "title": "Events at Rome R Users Group",
    "section": "",
    "text": "Events are the heartbeat of our community. They bring us together to learn, collaborate, and connect. Whether it‚Äôs a workshop, a meetup, or a project showcase, each event is an opportunity to share knowledge, build skills, and grow the R programming community in Rome and beyond.\nOur in-person focused group events are designed to foster deeper conversations and hands-on collaboration in smaller, interactive settings. Unlike large meetups, these sessions create space for participants to dive into specific topics, exchange ideas, and work through challenges side by side. By bringing people together in the same room, we create a supportive environment where learning feels personal, networking happens naturally, and everyone has a chance to contribute."
  },
  {
    "objectID": "content/events/index.html#upcoming-events",
    "href": "content/events/index.html#upcoming-events",
    "title": "Events at Rome R Users Group",
    "section": "Upcoming Events",
    "text": "Upcoming Events\n\nFor More Information about Next Events/Workshops/Tutorials Please Check: https://www.meetup.com/rome-r-users-group/"
  },
  {
    "objectID": "content/events/index.html#past-events",
    "href": "content/events/index.html#past-events",
    "title": "Events at Rome R Users Group",
    "section": "Past Events",
    "text": "Past Events"
  },
  {
    "objectID": "content/events/posts/01102025_inperson.html",
    "href": "content/events/posts/01102025_inperson.html",
    "title": "Rome in Person Meetup",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "content/events/posts/01052025.html",
    "href": "content/events/posts/01052025.html",
    "title": "Rome in Person Meetup",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "content/rhacks/posts/11282025-n1/index.html",
    "href": "content/rhacks/posts/11282025-n1/index.html",
    "title": "How to Add Images to ggplot Axes Using ggtext::element_markdown()\n",
    "section": "",
    "text": "This tip is based on a full Kaggle notebook, where this technique is applied in a complete Exploratory Data Analysis (EDA): üîó https://www.kaggle.com/code/lcolon/football-2023-2024-eda-and-pa-with-logos\n\nHave you ever needed to show logos, icons, or flags directly on the axes of your ggplot charts?\n\nYou can do this using the element_markdown() function from the {ggtext} package!\nelement_markdown() is a function that tells ggplot to treat labels as HTML instead of plain text. It must be used in the theme() section of your ggplot code.\nThe chart below shows an example where league logos appear directly on the x-axis. It displays the total number of goals scored in the major European football leagues during the 2023/2024 season:\n\n\n\nEuropean football leagues 2023/2024"
  },
  {
    "objectID": "content/rhacks/posts/11282025-n1/index.html#section",
    "href": "content/rhacks/posts/11282025-n1/index.html#section",
    "title": "How to Add Images to ggplot Axes Using ggtext::element_markdown()\n",
    "section": "",
    "text": "This tip is based on a full Kaggle notebook, where this technique is applied in a complete Exploratory Data Analysis (EDA): üîó https://www.kaggle.com/code/lcolon/football-2023-2024-eda-and-pa-with-logos\n\nHave you ever needed to show logos, icons, or flags directly on the axes of your ggplot charts?\n\nYou can do this using the element_markdown() function from the {ggtext} package!\nelement_markdown() is a function that tells ggplot to treat labels as HTML instead of plain text. It must be used in the theme() section of your ggplot code.\nThe chart below shows an example where league logos appear directly on the x-axis. It displays the total number of goals scored in the major European football leagues during the 2023/2024 season:\n\n\n\nEuropean football leagues 2023/2024"
  },
  {
    "objectID": "content/rhacks/posts/11282025-n1/index.html#exploratory-data-analysis-workflow",
    "href": "content/rhacks/posts/11282025-n1/index.html#exploratory-data-analysis-workflow",
    "title": "How to Add Images to ggplot Axes Using ggtext::element_markdown()\n",
    "section": "Exploratory Data Analysis Workflow",
    "text": "Exploratory Data Analysis Workflow\nHere is a short, practical guide showing how to recreate this plot.\nStep 0: Start from a basic dataframe\nIn most real situations you will already have a dataframe to work with. Here is the one used in this example:\n\ndf &lt;- data.frame(\n  league = c(\"Premier League\", \"La Liga\", \n             \"Serie A\", \"Bundesliga\", \"Ligue 1\"),\n  goals  = c(1197, 977, 968, 960, 804))\n\ndf\n\n          league goals\n1 Premier League  1197\n2        La Liga   977\n3        Serie A   968\n4     Bundesliga   960\n5        Ligue 1   804\n\n\nStep 1: Choose the images you want to display (PNG recommended)\nFirst decide which images you want to show on your ggplot axis. In this example I am using online image URLs (including links from Wikimedia), but you can use any source that provides a direct image URL, such as files hosted on GitHub repos or any public static hosting service. Just make sure the image format is supported ‚Äî typically PNG or JPG/JPEG.\n\n# Define image URLs as variables\npremier_url &lt;- \"https://upload.wikimedia.org/wikipedia/it/6/6d/Premier_League_Logo_2016.png\"\nlaliga_url &lt;- \"https://upload.wikimedia.org/wikipedia/it/9/9b/LFP_La_Liga.png\"\nseriea_url &lt;- \"https://www.fifplay.com/img/public/serie-a-logo.png\"\nbundes_url &lt;- \"https://www.fifplay.com/img/public/bundesliga-logo.png\"\nligue1_url &lt;- \"https://upload.wikimedia.org/wikipedia/commons/a/a0/Ligue_1_2024_Logo.png\"\n\nStep 2: Add a column with HTML  tags\nIn order to display images on the axis, each image URL must be wrapped inside an HTML  tag. This simply means that the URL cannot appear alone ‚Äî it must be placed inside the structure:\n`&lt;img src= + image_url + width='45'/&gt;`\nPlease note that in this example I use width=‚Äò45‚Äô just as a reference size, but you can choose any value depending on how big you want the image to appear in your plot.\nLet‚Äôs add the column to the df:\n\ndf$logo &lt;- c(\n  paste0(\"&lt;img src='\", premier_url, \"' width='45'/&gt;\"), \n  paste0(\"&lt;img src='\", laliga_url, \"' width='45'/&gt;\"), \n  paste0(\"&lt;img src='\", seriea_url, \"' width='45'/&gt;\"), \n  paste0(\"&lt;img src='\", bundes_url, \"' width='45'/&gt;\"), \n  paste0(\"&lt;img src='\", ligue1_url, \"' width='45'/&gt;\")\n  )\n\nAt this point, the dataframe should look like this:\n\n\n\n\n\n\n\n\nleague\ngoals\nlogo\n\n\n\nPremier League\n1197\n&lt;img src='https://upload.wikimedia.org/wikipedia/it/6/6d/Premier_League_Logo_2016.png' width='45'/&gt;\n\n\nLa Liga\n977\n&lt;img src='https://upload.wikimedia.org/wikipedia/it/9/9b/LFP_La_Liga.png' width='45'/&gt;\n\n\nSerie A\n968\n&lt;img src='https://www.fifplay.com/img/public/serie-a-logo.png' width='45'/&gt;\n\n\nBundesliga\n960\n&lt;img src='https://www.fifplay.com/img/public/bundesliga-logo.png' width='45'/&gt;\n\n\nLigue 1\n804\n&lt;img src='https://upload.wikimedia.org/wikipedia/commons/a/a0/Ligue_1_2024_Logo.png' width='45'/&gt;\n\n\n\n\nStep 3: Plot your data!\nNow that the dataframe contains a column of HTML  tags, we can use it directly on the x-axis. The key part is here:\n\ntheme( axis.text.x = element_markdown() )\n\nelement_markdown() function is what allows ggplot to interpret the HTML in your axis labels. Without it, ggplot would show the literal string &lt;img src='...'&gt; as plain text. With it, the &lt;img&gt; tags are rendered as actual images.\nHere is the full plotting code:\n\nlibrary(ggplot2)\nlibrary(ggtext)\n\n\noptions(repr.plot.width = 6, \n        repr.plot.height = 7, \n        warn = -1)\n\n\nggplot(df, \n       aes(x = reorder(logo, -goals), y = goals)) + \n  geom_col(fill = \"forestgreen\", width = .8) +\n  geom_text(aes(label = goals), vjust = -0.5, size = 4.5) + \n  labs(title = \"\\nFootball stats 2023/2024\",\n       subtitle = \"Total Goals scored in each League\\n\" ) + \n  theme_minimal(14) +\n  # HTML rendering happens here!!\n  theme(axis.text.x = ggtext::element_markdown(), \n         axis.text.y = element_blank(), \n         panel.grid = element_blank(), \n         axis.title = element_blank(), \n         plot.title = element_text(face = \"bold\", \n                                   colour = \"blue\", hjust = 0.05), \n         plot.subtitle= element_text(hjust = 0.05)\n         )\n\nWith element_markdown() applied to axis.text.x, ggplot correctly displays the league logos instead of plain text labels, as seen in the barchart above.\nTo Recap\n\nPrepare your dataframe (existing or new)\nChoose your images (PNG recommended) and store their URLs\nWrap each URL inside an HTML tag with a defined width\nAdd this HTML column to your dataframe\nMap it to the ggplot axis\nEnable HTML rendering in plot theme using:\n\n\naxis.text.x = ggtext::element_markdown()\n\nThanks for reading!\n\n\n\n\n\n\nTip\n\n\n\nIf you want to stay up to date with the latest events from the Rome R Users Group, click here:\nüëâhttps://www.meetup.com/rome-r-users-group/\nAnd if you are curious, the full Kaggle notebook used for this tip is available here: üîóhttps://www.kaggle.com/code/lcolon/football-2023-2024-eda-and-pa-with-logos"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html",
    "href": "content/rhacks/posts/01232026-n4/index.html",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "",
    "text": "This hack is based on my analysis on Kaggle analysis linked as follows (please see Chapter 4.3):\nüîó https://www.kaggle.com/code/lcolon/exploring-2024-software-engineer-salaries\nWhen exploring a distribution, a very common question is:\nShowing only the Top values might hid some context, while showing two separate charts can make comparison harder.\nThis R-Hack shows a simple and reusable pattern to display Top and Bottom values together in a single, clean visualization, as the one showed below:"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html#step-0-create-an-example-dataset",
    "href": "content/rhacks/posts/01232026-n4/index.html#step-0-create-an-example-dataset",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "Step 0 ‚Äì Create an example dataset",
    "text": "Step 0 ‚Äì Create an example dataset\nLet‚Äôs start from a small, simulated dataset representing average salaries for different companies:\n\nlibrary(tidyverse)\n\nset.seed(123)\n\ndf &lt;- data.frame(\n  company = (LETTERS[1:26]),\n  avg_salary = round(runif(26, min = 60, max = 180), 0)\n)\n\nhead(df)\n\n  company avg_salary\n1       A         95\n2       B        155\n3       C        109\n4       D        166\n5       E        173\n6       F         65"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html#step-1-build-top-bottom-datasets-in-a-single-pipeline",
    "href": "content/rhacks/posts/01232026-n4/index.html#step-1-build-top-bottom-datasets-in-a-single-pipeline",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "Step 1 ‚Äì Build Top & Bottom datasets in a single pipeline",
    "text": "Step 1 ‚Äì Build Top & Bottom datasets in a single pipeline\nIn this step, we extract both the Top 10 and Bottom 10 values using a single, readable pipeline.\nThe idea is simple. Starting from the same dataset:\n\nselect the Top 10 by applying slice_max(), which returns all observations within the top 10 ranking positions, including any ties\nselect the Bottom 10 by applying slice_min(), returning all observations within the lowest 10 ranking positions, again including ties\nassign a clear group label to each subset\ncombine the two subsets into a single dataframe for visualization and further analysis\n\n\nplot_df &lt;- \n  bind_rows(\n    df %&gt;% \n      slice_max(avg_salary, n = 10, with_ties = TRUE) %&gt;%\n      mutate(group = \"Top 10\"),\n    \n    df %&gt;% \n      slice_min(avg_salary, n = 10, with_ties = TRUE) %&gt;%\n      mutate(group = \"Bottom 10\")\n  )\n\nhead(plot_df)\n\n  company avg_salary  group\n1       X        179 Top 10\n2       K        175 Top 10\n3       T        175 Top 10\n4       E        173 Top 10\n5       P        168 Top 10\n6       H        167 Top 10"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html#step-2---plot-the-data",
    "href": "content/rhacks/posts/01232026-n4/index.html#step-2---plot-the-data",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "Step 2 - Plot the data",
    "text": "Step 2 - Plot the data\nIn this step, starting from the dataframe created in the previous step, we build a simple visualization with ggplot:\n\nplot_base &lt;- ggplot(plot_df, \n                    aes(x = reorder(company, -avg_salary), y = avg_salary)) +\n  geom_col(fill = \"steelblue\") +\n  geom_text(aes(label = avg_salary), vjust = -0.4, size = 4) +\n  facet_wrap(~ fct_rev(group), scales = \"free_x\") +\n  labs(\n    title = \"Top and Bottom Companies by Average Salary\",\n    subtitle = \"Simulated data example\\n\\n\",\n    y = \"Average yearly salary\",\n    x = NULL\n  ) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),\n    axis.text.x = element_text(size = 10),\n    axis.text.y = element_blank()\n  )\n\nplot_base"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html#step-3---generate-gradient-color-palettes",
    "href": "content/rhacks/posts/01232026-n4/index.html#step-3---generate-gradient-color-palettes",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "Step 3 - Generate gradient color palettes",
    "text": "Step 3 - Generate gradient color palettes\nNow that the base chart is working, we can make it more informative by adding two gradient color palettes:\n\none gradient for the Top group (blue shades)\none gradient for the Bottom group (red shades)\n\nInstead of assigning a single color per group, we assign a slightly different shade to each bar. This creates a clean gradient effect while keeping the plot readable ‚Äî even when ties produce more than 10 observations per group.\nTo do this, we:\n\ngenerate a group-specific palette with colorRampPalette(), sized to the number of rows in each group (so it adapts if ties expand the selection)\ngroup the data by group (Top vs Bottom)\nassign colors row by row using row_number()\n\nstore the result in a new column called color\n\n\n\nplot_df &lt;- plot_df %&gt;%\n  group_by(group) %&gt;%\n  mutate(\n    color = if_else(\n      group == \"Top 10\",\n      colorRampPalette(c(\"darkblue\", \"lightblue\"))(n())[row_number()],\n      colorRampPalette(c(\"darkred\", \"lightcoral\"))(n())[row_number()]\n    )\n  ) %&gt;%\n  ungroup()\n\nhead(plot_df)\n\n# A tibble: 6 √ó 4\n  company avg_salary group  color  \n  &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt;  \n1 X              179 Top 10 #00008B\n2 K              175 Top 10 #131895\n3 T              175 Top 10 #26309F\n4 E              173 Top 10 #3948A9\n5 P              168 Top 10 #4C60B3\n6 H              167 Top 10 #6078BD"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html#step-4---style-the-chart-using-the-new-colors",
    "href": "content/rhacks/posts/01232026-n4/index.html#step-4---style-the-chart-using-the-new-colors",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "Step 4 - Style the chart using the new colors",
    "text": "Step 4 - Style the chart using the new colors\nAt this point, we don‚Äôt want to rewrite the entire ggplot call. Instead, we:\n\nreuse the base chart (plot_base)\nreplace its dataset with the updated plot_df (the one that now includes color) using the %+% operator\nadd a new geom_col() that maps fill to the color column\nuse scale_fill_identity() so ggplot uses the colors as they are listed in the color column\n\n\nplot_styled &lt;- (plot_base %+% plot_df) +\n  geom_col(aes(fill = color)) +\n  scale_fill_identity()\n\nplot_styled"
  },
  {
    "objectID": "content/rhacks/posts/01232026-n4/index.html#in-short",
    "href": "content/rhacks/posts/01232026-n4/index.html#in-short",
    "title": "R-Hacks | Showing Top & Bottom values in one clear visualization",
    "section": "In short",
    "text": "In short\n\nExtract Top 10 and Bottom 10 values from the same dataset using slice_max() and slice_min(), including ties\nCombine the two subsets into a single dataframe for a compact overview of the distribution extremes\nBuild a clean base plot to validate structure and layout\nEnhance the visualization by applying gradient colors to distinguish Top and Bottom groups\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to stay up to date with the latest events from the Rome R Users Group, click here:\nüëâ https://www.meetup.com/rome-r-users-group/\nAnd if you are curious, the full Kaggle notebook used for this tip is available here:\nüîó https://www.kaggle.com/code/lcolon/exploring-2024-software-engineer-salaries"
  },
  {
    "objectID": "content/news/index.html",
    "href": "content/news/index.html",
    "title": "R Consortium Events & Workshops",
    "section": "",
    "text": "Stay updated with the latest news and resources from the R community. Here are some valuable links to keep you informed and connected:"
  },
  {
    "objectID": "content/news/index.html#news",
    "href": "content/news/index.html#news",
    "title": "R Consortium Events & Workshops",
    "section": "",
    "text": "Stay updated with the latest news and resources from the R community. Here are some valuable links to keep you informed and connected:"
  },
  {
    "objectID": "content/news/index.html#check-recent-posts-from-selected-r-and-data-science-sources",
    "href": "content/news/index.html#check-recent-posts-from-selected-r-and-data-science-sources",
    "title": "R Consortium Events & Workshops",
    "section": "Check recent posts from selected R and data science sources:",
    "text": "Check recent posts from selected R and data science sources:\n\n\n\n\n\n\nDate\nSource\nTitle\n\n\n\n\n2026-01-12\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2026-W03 R & Python Pluralism, RAG Setup, tinyshinyserver\n\n\n\n2025-12-22\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W52 Festive ML, next gen R contributors, The Economist style ggplot2\n\n\n\n2025-12-16\nR-Ladies Rome\nFrom Basics to Advanced Health Analytics: Exploring Diabetes Data\n\n\n\n2025-12-15\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W51 data visualisation, assess usage of your package, mutagen\n\n\n\n2025-12-08\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W50 New AI Newsletter, Test Set on Youtube, Haskell for Data Science\n\n\n\n2025-12-01\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W49 Custom GPS, testing, Tribal Councils\n\n\n\n2025-11-24\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W48 Multi-agents, linter, rbranding\n\n\n\n2025-11-17\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W47 Plots, Tables, Pipes\n\n\n\n2025-11-10\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W46 Custom ggplot2 geoms, data.table, NYC election\n\n\n\n2025-11-04\nRWeekly.org - Blogs to Learn R from the Community\nR Weekly 2025-W45 Pledging my time, neon ghosts, bioconductor release"
  },
  {
    "objectID": "LICENSE.html",
    "href": "LICENSE.html",
    "title": "MIT License",
    "section": "",
    "text": "MIT License\nCopyright (c) 2025 Rome-R-Users-Group authors\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the ‚ÄúSoftware‚Äù), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED ‚ÄúAS IS‚Äù, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "content/resources/index.html",
    "href": "content/resources/index.html",
    "title": "Rome R-Users Group",
    "section": "",
    "text": "Some recommended R books‚Ä¶\n\nR for Data Science by Hadley Wickham & Garrett Grolemund - A comprehensive guide to data science using R and the tidyverse.\n\nAdvanced R by Hadley Wickham - A deep dive into the R programming language and its advanced features.\nThe Art of R Programming by Norman Matloff - A thorough introduction to R programming for beginners and experienced programmers alike.\nR in Action by Robert Kabacoff - A practical guide to R with numerous examples and case studies.\nData Science with R by Garrett Grolemund & Hadley Wickham - A hands-on guide to data science using R.\nPractical Statistics for Data Scientists by Peter Bruce & Andrew Bruce - A practical guide to statistical methods for data science using R.\n\n\n\n\nList of R packages containers‚Ä¶\n\nCRAN - The Comprehensive R Archive Network, the primary repository for R packages.\nBioconductor - A repository for bioinformatics and computational biology packages in R.\nRopensci - A collection of R packages for open science and reproducible research.\n\n\n\n\nLinks to tutorials‚Ä¶\n\nRStudio Education - A variety of tutorials and resources for learning R and RStudio.\nSwirl - An interactive learning platform that teaches R programming and data science directly in the R console.\nDataCamp - Online courses and tutorials for learning R and data science.\nCoursera R Courses - A variety of R programming courses available on Coursera.\nYouTube Channels - Numerous channels and videos dedicated to R programming and data science.\n\n\n\n\nUseful references‚Ä¶\n\nRStudio Cheatsheets - Handy reference sheets for various R packages and functions.\nCRAN Task Views - Curated lists of R packages for specific topics.\nTidyverse - A collection of R packages designed for data science."
  },
  {
    "objectID": "content/resources/index.html#resources",
    "href": "content/resources/index.html#resources",
    "title": "Rome R-Users Group",
    "section": "",
    "text": "Some recommended R books‚Ä¶\n\nR for Data Science by Hadley Wickham & Garrett Grolemund - A comprehensive guide to data science using R and the tidyverse.\n\nAdvanced R by Hadley Wickham - A deep dive into the R programming language and its advanced features.\nThe Art of R Programming by Norman Matloff - A thorough introduction to R programming for beginners and experienced programmers alike.\nR in Action by Robert Kabacoff - A practical guide to R with numerous examples and case studies.\nData Science with R by Garrett Grolemund & Hadley Wickham - A hands-on guide to data science using R.\nPractical Statistics for Data Scientists by Peter Bruce & Andrew Bruce - A practical guide to statistical methods for data science using R.\n\n\n\n\nList of R packages containers‚Ä¶\n\nCRAN - The Comprehensive R Archive Network, the primary repository for R packages.\nBioconductor - A repository for bioinformatics and computational biology packages in R.\nRopensci - A collection of R packages for open science and reproducible research.\n\n\n\n\nLinks to tutorials‚Ä¶\n\nRStudio Education - A variety of tutorials and resources for learning R and RStudio.\nSwirl - An interactive learning platform that teaches R programming and data science directly in the R console.\nDataCamp - Online courses and tutorials for learning R and data science.\nCoursera R Courses - A variety of R programming courses available on Coursera.\nYouTube Channels - Numerous channels and videos dedicated to R programming and data science.\n\n\n\n\nUseful references‚Ä¶\n\nRStudio Cheatsheets - Handy reference sheets for various R packages and functions.\nCRAN Task Views - Curated lists of R packages for specific topics.\nTidyverse - A collection of R packages designed for data science."
  },
  {
    "objectID": "content/rhacks/posts/12052025-n2/index.html",
    "href": "content/rhacks/posts/12052025-n2/index.html",
    "title": "R Hack ‚Äì Getting started with maps in R using GeoJSON and library sf",
    "section": "",
    "text": "This hack is based on my Cyclistic analysis on Kaggle (see Chapter 8.12.4):\nüîó https://www.kaggle.com/code/lcolon/cyclistic-2023-google-da-capstone-project-r\nWorking with maps in R is easier than it seems.\nIf you want to visualize points, regions, or spatial patterns, the combination of GeoJSON files and the sf package gives you a simple and modern workflow.\nIn this hack, we‚Äôll load a real city map (Chicago) directly from a URL, plot it with geom_sf(), and overlay simple point data."
  },
  {
    "objectID": "content/rhacks/posts/12052025-n2/index.html#step-0-what-is-a-geojson-file",
    "href": "content/rhacks/posts/12052025-n2/index.html#step-0-what-is-a-geojson-file",
    "title": "R Hack ‚Äì Getting started with maps in R using GeoJSON and library sf",
    "section": "Step 0 ‚Äì What is a GeoJSON file?",
    "text": "Step 0 ‚Äì What is a GeoJSON file?\nA GeoJSON file is a JSON text file that stores geographic shapes (points, lines, polygons), together with their attributes (names, boundaries, codes, etc.).\nIt is one of the most common formats for open geographic data because it is lightweight, human-readable, and web-friendly.\nYou can often find GeoJSON files on:\n\ncity open data portals (City of Chicago, NYC Open Data, etc.)\n\nnational and international platforms (e.g., data.gov)\n\nGitHub repositories\n\nmany public mapping resources"
  },
  {
    "objectID": "content/rhacks/posts/12052025-n2/index.html#step-1-load-the-required-packages",
    "href": "content/rhacks/posts/12052025-n2/index.html#step-1-load-the-required-packages",
    "title": "R Hack ‚Äì Getting started with maps in R using GeoJSON and library sf",
    "section": "Step 1 ‚Äì Load the required packages",
    "text": "Step 1 ‚Äì Load the required packages\n\nlibrary(sf)       # for spatial data (simple features)\nlibrary(ggplot2)  # for plotting"
  },
  {
    "objectID": "content/rhacks/posts/12052025-n2/index.html#step-2-read-a-geojson-map-with-sfst_read",
    "href": "content/rhacks/posts/12052025-n2/index.html#step-2-read-a-geojson-map-with-sfst_read",
    "title": "R Hack ‚Äì Getting started with maps in R using GeoJSON and library sf",
    "section": "Step 2 ‚Äì Read a GeoJSON map with sf::st_read()\n",
    "text": "Step 2 ‚Äì Read a GeoJSON map with sf::st_read()\n\nIn this hack, we use a GeoJSON of Chicago community areas, provided by the City of Chicago Open Data Portal.\n‚ö†Ô∏è Before using any online map or dataset, always remember to check the terms of use of the source.\nYou can read a GeoJSON directly from a URL, without downloading anything manually:\n\nmap_of_chicago &lt;- sf::st_read(\n  \"https://data.cityofchicago.org/resource/y6yq-dbs2.geojson\",\n  quiet = TRUE\n  )\n\nhead(map_of_chicago)\n\nSimple feature collection with 6 features and 4 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -87.74141 ymin: 41.80189 xmax: -87.60641 ymax: 41.93272\nGeodetic CRS:  WGS 84\n           pri_neigh          sec_neigh    shape_area    shape_len\n1    Grand Boulevard        BRONZEVILLE 48492503.1554 28196.837157\n2       Printers Row       PRINTERS ROW 2162137.97139  6864.247156\n3      United Center      UNITED CENTER 32520512.7053 23101.363745\n4 Sheffield & DePaul SHEFFIELD & DEPAUL 10482592.2987 13227.049745\n5      Humboldt Park      HUMBOLDT PARK 125010425.593 46126.751351\n6      Garfield Park      GARFIELD PARK 89976069.5947  44460.91922\n                        geometry\n1 MULTIPOLYGON (((-87.60671 4...\n2 MULTIPOLYGON (((-87.62761 4...\n3 MULTIPOLYGON (((-87.66707 4...\n4 MULTIPOLYGON (((-87.65833 4...\n5 MULTIPOLYGON (((-87.7406 41...\n6 MULTIPOLYGON (((-87.6954 41...\n\n\n\nWhat you get:\n\n\nmap_of_chicago is an sf object -essentially a data frame with a special geometry column where each row is a polygon that represents one community area"
  },
  {
    "objectID": "content/rhacks/posts/12052025-n2/index.html#step-3-plot-a-basic-map-with-geom_sf",
    "href": "content/rhacks/posts/12052025-n2/index.html#step-3-plot-a-basic-map-with-geom_sf",
    "title": "R Hack ‚Äì Getting started with maps in R using GeoJSON and library sf",
    "section": "Step 3 ‚Äì Plot a basic map with geom_sf()\n",
    "text": "Step 3 ‚Äì Plot a basic map with geom_sf()\n\nOnce the GeoJSON file has been loaded into an sf object, you can visualize it with geom_sf().\ngeom_sf() is the ggplot2 layer designed specifically for spatial data: it knows how to read the geometry column of an sf object and automatically draw points, lines, or polygons depending on what the data contains. In our case, it will draw the polygons of Chicago‚Äôs community areas.\n\nggplot() +\n  geom_sf(data = map_of_chicago, \n          fill = \"#f1f0f0\", color = \"grey50\") +\n  labs(title = \"Chicago community areas\",\n       subtitle = \"GeoJSON map loaded with sf::st_read()\") +\n  theme_void()"
  },
  {
    "objectID": "content/rhacks/posts/12052025-n2/index.html#to-recap",
    "href": "content/rhacks/posts/12052025-n2/index.html#to-recap",
    "title": "R Hack ‚Äì Getting started with maps in R using GeoJSON and library sf",
    "section": "To Recap",
    "text": "To Recap\n\nGeoJSON = JSON file with geometry + attributes\nLoad it directly from a URL with sf::st_read()\nPlot it with geom_sf()\nAdd your own points using regular ggplot layers\nThis workflow is simple, beginner-friendly, and requires no GIS tools\n\n\nThanks for reading!\n\n\n\n\n\n\nTip\n\n\n\nIf you want to stay up to date with the latest events from the Rome R Users Group, click here:\nüëâ https://www.meetup.com/rome-r-users-group/\nAnd if you are curious, the full Kaggle notebook used for this tip is available here:\nüîó https://www.kaggle.com/code/lcolon/cyclistic-2023-google-da-capstone-project-r"
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html",
    "href": "content/rhacks/posts/01132026-n3/index.html",
    "title": "Compare multiple dataframes before binding them together",
    "section": "",
    "text": "Create your function\n\nThis hack is based on my Cyclistic analysis on Kaggle (see Chapter 6.3):\nüîó https://www.kaggle.com/code/lcolon/cyclistic-2023-google-da-capstone-project-r\nWhen working with multiple datasets a common question is:\n\nAre these dataframes really compatible before I bind them together?\n\nPeople who work with data typically rely on a mix of approaches to answer this:\nmanual checks (names(), glimpse()), warnings raised by bind_rows(), or dedicated helpers such as compare_df_cols() from the janitor package ‚Äî which is a solid and widely used solution for comparing column structures.\nHowever, in practice, it is often useful to have a single, lightweight helper that provides a compact and readable overview across many dataframes at once, without additional dependencies or verbose output.\nThis R Hack introduces a small custom helper function designed with that goal in mind, that you can easily reuse and adapt to your own workflows.\nIt performs an omnicomprehensive structural comparison before merging, checking column count, column names, and column classes across all pairs of dataframes:\n\n#   comparison   same_ncol same_names same_class\n#   &lt;chr&gt;        &lt;lgl&gt;     &lt;lgl&gt;      &lt;lgl&gt;     \n# 1 df_a vs df_b TRUE      TRUE       TRUE      \n# 2 df_a vs df_c TRUE      TRUE       FALSE     \n# 3 df_a vs df_d TRUE      FALSE      FALSE     \n# 4 df_b vs df_c TRUE      TRUE       FALSE     \n# 5 df_b vs df_d TRUE      FALSE      FALSE     \n# 6 df_c vs df_d TRUE      FALSE      FALSE"
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html#section",
    "href": "content/rhacks/posts/01132026-n3/index.html#section",
    "title": "Compare multiple dataframes before binding them together",
    "section": "",
    "text": "Create your function\n\nThis hack is based on my Cyclistic analysis on Kaggle (see Chapter 6.3):\nüîó https://www.kaggle.com/code/lcolon/cyclistic-2023-google-da-capstone-project-r\nWhen working with multiple datasets a common question is:\n\nAre these dataframes really compatible before I bind them together?\n\nPeople who work with data typically rely on a mix of approaches to answer this:\nmanual checks (names(), glimpse()), warnings raised by bind_rows(), or dedicated helpers such as compare_df_cols() from the janitor package ‚Äî which is a solid and widely used solution for comparing column structures.\nHowever, in practice, it is often useful to have a single, lightweight helper that provides a compact and readable overview across many dataframes at once, without additional dependencies or verbose output.\nThis R Hack introduces a small custom helper function designed with that goal in mind, that you can easily reuse and adapt to your own workflows.\nIt performs an omnicomprehensive structural comparison before merging, checking column count, column names, and column classes across all pairs of dataframes:\n\n#   comparison   same_ncol same_names same_class\n#   &lt;chr&gt;        &lt;lgl&gt;     &lt;lgl&gt;      &lt;lgl&gt;     \n# 1 df_a vs df_b TRUE      TRUE       TRUE      \n# 2 df_a vs df_c TRUE      TRUE       FALSE     \n# 3 df_a vs df_d TRUE      FALSE      FALSE     \n# 4 df_b vs df_c TRUE      TRUE       FALSE     \n# 5 df_b vs df_d TRUE      FALSE      FALSE     \n# 6 df_c vs df_d TRUE      FALSE      FALSE"
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html#step-0-create-example-dataframes-to-compare",
    "href": "content/rhacks/posts/01132026-n3/index.html#step-0-create-example-dataframes-to-compare",
    "title": "Compare multiple dataframes before binding them together",
    "section": "Step 0 ‚Äì Create example dataframes to compare",
    "text": "Step 0 ‚Äì Create example dataframes to compare\nTo make the idea concrete, let‚Äôs create four small dataframes. Some of them match perfectly, others don‚Äôt:\n\ndf_a &lt;- data.frame(\n  id = 1:3,\n  value = c(10, 20, 30)\n)\n\ndf_b &lt;- data.frame(\n  id = 4:6,\n  value = c(40, 50, 60)\n)\n\n# Same columns, but different class for `value`\ndf_c &lt;- data.frame(\n  id = 7:9,\n  value = as.character(c(70, 80, 90))\n)\n\n# Different column name\ndf_d &lt;- data.frame(\n  id = 10:12,\n  amount = c(100, 200, 300)\n)"
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html#step-1-define-the-helper-function-to-compare-dataframes",
    "href": "content/rhacks/posts/01132026-n3/index.html#step-1-define-the-helper-function-to-compare-dataframes",
    "title": "Compare multiple dataframes before binding them together",
    "section": "Step 1 ‚Äì Define the helper function to compare dataframes",
    "text": "Step 1 ‚Äì Define the helper function to compare dataframes\nThe function below takes a vector of dataframe names (as character strings) and compares each unique pair only once. It works in three simple steps:\n\nIt loads the dataframes from the environment using their names\nIt iterates over all unique dataframe combinations, ensuring that each pair is checked only once (for example, it compares df_a vs df_b, but not df_b vs df_a))\n\nFor each pair, it performs the following structural checks and stores the results in a tibble:\n\nwhether the number of columns matches\nwhether column names are identical\nwhether column classes are the same\n\n\n\nThe function then binds all tibbles together into a single summary table, making it easy to spot structural mismatches before combining the data.\n\nlibrary(tidyverse)\ncompare_dataframes &lt;- function(df_names) {\n\n  # Get DF names\n  df_list &lt;- lapply(df_names, get)\n\n  # Initialize an empty list\n  results &lt;- list()\n\n  # Selection of DF pairs to be compared\n  for (i in seq_len(length(df_list) - 1)) {\n    for (j in (i + 1):length(df_list)) {\n\n      results[[length(results) + 1]] &lt;- tibble(\n        comparison = paste(df_names[i], \"vs\", df_names[j]),\n\n        # check number of columns\n        same_ncol  = ncol(df_list[[i]]) == ncol(df_list[[j]]),\n\n        # check columns name\n        same_names = identical(names(df_list[[i]]), names(df_list[[j]])),\n\n        # check columns class\n        same_class = identical(\n          sapply(df_list[[i]], class),\n          sapply(df_list[[j]], class)\n        )\n      )\n    }\n  }\n\n  comparison_result &lt;- bind_rows(results)\n  return(comparison_result)\n}"
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html#step-2-apply-the-function",
    "href": "content/rhacks/posts/01132026-n3/index.html#step-2-apply-the-function",
    "title": "Compare multiple dataframes before binding them together",
    "section": "Step 2 ‚Äì Apply the function",
    "text": "Step 2 ‚Äì Apply the function\nProvide the dataframe names as a character vector and invoke the function:\n\ndf_names &lt;- c(\"df_a\", \"df_b\", \"df_c\", \"df_d\")\n\ncomparison_result &lt;- compare_dataframes(df_names)\n\ncomparison_result\n\n# A tibble: 6 √ó 4\n  comparison   same_ncol same_names same_class\n  &lt;chr&gt;        &lt;lgl&gt;     &lt;lgl&gt;      &lt;lgl&gt;     \n1 df_a vs df_b TRUE      TRUE       TRUE      \n2 df_a vs df_c TRUE      TRUE       FALSE     \n3 df_a vs df_d TRUE      FALSE      FALSE     \n4 df_b vs df_c TRUE      TRUE       FALSE     \n5 df_b vs df_d TRUE      FALSE      FALSE     \n6 df_c vs df_d TRUE      FALSE      FALSE"
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html#step-3-interpret-the-results",
    "href": "content/rhacks/posts/01132026-n3/index.html#step-3-interpret-the-results",
    "title": "Compare multiple dataframes before binding them together",
    "section": "Step 3 ‚Äì Interpret the results",
    "text": "Step 3 ‚Äì Interpret the results\nThe output table makes structural mismatches immediately visible:\nsame_ncol ‚Üí different number of columns\nsame_names ‚Üí different column names\nsame_class ‚Üí same columns, but different data types\nIn the example provided:\ndf_a vs df_b ‚Üí all TRUE (safe to bind)\ndf_a vs df_c ‚Üí same_class = FALSE\ndf_a vs df_d ‚Üí same_names = FALSE\nThis helps you catch issues before they turn into silent bugs."
  },
  {
    "objectID": "content/rhacks/posts/01132026-n3/index.html#in-short",
    "href": "content/rhacks/posts/01132026-n3/index.html#in-short",
    "title": "Compare multiple dataframes before binding them together",
    "section": "In short",
    "text": "In short\n\nThere is no single ‚Äúofficial‚Äù way to compare many dataframes at once\nHelpers like compare_df_cols() from janitor are excellent for column-level inspection\nThis custom helper function provides a clear, compact overview before stacking or merging data\nThink of it as a pre-flight checklist before combining your data\n\n\n\n\n\n\n\n\nTip\n\n\n\nIf you want to stay up to date with the latest events from the Rome R Users Group, click here:\nüëâ https://www.meetup.com/rome-r-users-group/\nAnd if you are curious, the full Kaggle notebook used for this tip is available here:\nüîó https://www.kaggle.com/code/lcolon/cyclistic-2023-google-da-capstone-project-r"
  },
  {
    "objectID": "content/rhacks/index.html#section",
    "href": "content/rhacks/index.html#section",
    "title": "R-Hacks",
    "section": "",
    "text": "R-Hacks specialises in short, focused examples that solve a concrete problem. No long tutorials, no heavy theory‚Äîjust the exact piece of code you need right now. From quick ggplot adjustments to clever data wrangling patterns, each snippet is built to be copied, adapted, and used immediately in your own analysis.\nBeyond simple tricks, the blog highlights efficient ways of thinking about data. You‚Äôll find micro-workflows that combine tidyverse tools, reproducible visualisation techniques, and small utilities that make routine tasks easier. Every post aims to help you write cleaner, faster, and more robust R code by adopting sensible, modern practices.\nR-Hacks is powered by the Rome R Users Group community. We collect clever ideas, handy functions, and small daily discoveries shared during meetups or projects. The goal is to create a living library of high-impact examples that reflect what people actually use in their analysis‚Äînot theoretical snippets, but real solutions to real problems."
  },
  {
    "objectID": "content/events/posts/01062025_inperson.html",
    "href": "content/events/posts/01062025_inperson.html",
    "title": "Rome in Person Meetup",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html",
    "href": "content/events/posts/27112025_jakubnowosad.html",
    "title": "R for geospatial predictive mapping",
    "section": "",
    "text": "Registered Attendees (203)"
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#overview",
    "href": "content/events/posts/27112025_jakubnowosad.html#overview",
    "title": "R for geospatial predictive mapping",
    "section": "Overview",
    "text": "Overview\nOn November 27, the Rome R Users Group hosted a special workshop led by Jakub Nowosad, one of the most recognized voices in the R spatial community. More than 200 participants registered for the event, marking one of our largest and most engaging sessions to date. For those who couldn‚Äôt attend live, or who wish to revisit the material‚Äîthis page includes the recording and all essential information so you can follow the workshop at your own pace.\n\nA Deep Dive into Geospatial Predictive Mapping\nThe workshop focused on practical workflows for building reliable spatial predictions in R. Much of the discussion revolved around the challenges of predicting spatial patterns in real-world contexts, where data often contain gaps, biases, or irregular sampling.\nJakub demonstrated how R can be used not only to model such data but also to valuate model performance spatially and visualize results in ways that highlight both strengths and limitations. Concepts like spatial cross-validation, the Area of Applicability (AoA), and prediction-domain adaptive diagnostics were explained clearly, illustrating why traditional modeling approaches often fall short when applied to geographic problems.\nThroughout the session, participants followed concrete examples showing how various R packages, such as {sf}, {terra}, {CAST} and several visualization tools, including {tmap}, work together within a workflow. The emphasis is on reproducibility and transparent code. The workshop is particularly valuable for practitioners working in environmental analysis, ecology, remote sensing, and related fields."
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#about-the-speaker",
    "href": "content/events/posts/27112025_jakubnowosad.html#about-the-speaker",
    "title": "R for geospatial predictive mapping",
    "section": "About the Speaker",
    "text": "About the Speaker\nJakub Nowosad is an Associate Professor at the Adam Mickiewicz University in Poznan and a Visiting Scientist at University of M√ºnster, specializing in geospatial data analysis and R programming. He is the author of Geocomputation with R, a comprehensive resource for spatial data science in R. A Python version of the book has also been released recently and can be found at https://py.geocompx.org/. Jakub has developed many R packages for spatial data manipulation and visualization, and has contributed extensively to the R community through workshops, tutorials, and publications."
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#watch-the-recording",
    "href": "content/events/posts/27112025_jakubnowosad.html#watch-the-recording",
    "title": "R for geospatial predictive mapping",
    "section": "Watch the Recording",
    "text": "Watch the Recording\nIf you missed the live workshop, you can watch the recording here:\nüé¨ Watch the Video Now\nSimply click on the video below to catch up on the discussion:\n\nThe recording includes the full demonstration, slides, and the audience Q&A session."
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#materials-and-resources",
    "href": "content/events/posts/27112025_jakubnowosad.html#materials-and-resources",
    "title": "R for geospatial predictive mapping",
    "section": "Materials and Resources",
    "text": "Materials and Resources\nYou can access the workshop materials, including slides and code examples, on Jakub Nowosad‚Äôs website:\n\nWorkshop Materials\n\n\n\n\n\n\n\nTip\n\n\n\nNote: The materials include all R scripts and datasets used during the workshop, allowing you to follow along and practice the techniques demonstrated.\n\nUse the left/right arrow keys on your keyboard to navigate the presentation.\n\nTo explore the code used in the workshop, click the arrow button on the side of the slides."
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#learning-objectives",
    "href": "content/events/posts/27112025_jakubnowosad.html#learning-objectives",
    "title": "R for geospatial predictive mapping",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this workshop, participants will be able to: - Build predictive models using spatial data - Validate the results in a robust way - Visualize geospatial data and model outputs effectively"
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#topics-covered",
    "href": "content/events/posts/27112025_jakubnowosad.html#topics-covered",
    "title": "R for geospatial predictive mapping",
    "section": "Topics Covered",
    "text": "Topics Covered\n\nIntroduction to geocomputational methods\nBuilding predictive models using spatial data\nValidating the models results\nVisualization techniques for geospatial data"
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#what-participants-learned",
    "href": "content/events/posts/27112025_jakubnowosad.html#what-participants-learned",
    "title": "R for geospatial predictive mapping",
    "section": "What Participants Learned",
    "text": "What Participants Learned\nRather than treating geospatial modeling as a sequence of isolated steps, Jakub encouraged a holistic perspective. Participants saw how the process begins with understanding the structure and quality of spatial data, continues through careful model training and selection, and culminates in interpreting predictions within their geographical context.\nParticular attention was given to the pitfalls that arise when spatial structure is ignored‚Äîfor example, overly optimistic accuracy metrics or unrealistic prediction maps. Jakub explained how spatially aware resampling strategies lead to more reliable evaluations and how tools like the AoA metric help determine where a model should or should not be trusted.\nVisualisation was another central theme. The workshop demonstrated how thoughtful map design can communicate both predictions and associated uncertainties, promoting transparent and responsible modeling."
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#who-is-this-workshop-for",
    "href": "content/events/posts/27112025_jakubnowosad.html#who-is-this-workshop-for",
    "title": "R for geospatial predictive mapping",
    "section": "Who Is This Workshop For?",
    "text": "Who Is This Workshop For?\nThis workshop is ideal for data scientists, GIS professionals, and R users interested in advancing their skills in geospatial predictive mapping. A basic understanding of R programming and spatial data concepts is recommended."
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#what-do-you-need-to-follow-along",
    "href": "content/events/posts/27112025_jakubnowosad.html#what-do-you-need-to-follow-along",
    "title": "R for geospatial predictive mapping",
    "section": "What Do You Need to Follow Along?",
    "text": "What Do You Need to Follow Along?\nParticipants interested in reproducing the code demonstrated during the workshop should ensure that, in addition to having R and RStudio installed, the following R packages are available:\n\nsf\n\nterra\n\ncaret\n\nCAST\ntmap"
  },
  {
    "objectID": "content/events/posts/27112025_jakubnowosad.html#contact",
    "href": "content/events/posts/27112025_jakubnowosad.html#contact",
    "title": "R for geospatial predictive mapping",
    "section": "Contact",
    "text": "Contact\nFor more information about the workshop, please contact us at romerusersgroup@gmail.com.\n\n‚ÄúWe look forward to seeing you there!‚Äù"
  },
  {
    "objectID": "about/organizers.html",
    "href": "about/organizers.html",
    "title": "Organizers",
    "section": "",
    "text": "Note\n\n\n\nThe Rome R Users Group was founded in 2025 by Federica Gazzelloni to connect and support R users, data scientists, and enthusiasts across Rome."
  },
  {
    "objectID": "about/organizers.html#section",
    "href": "about/organizers.html#section",
    "title": "Organizers",
    "section": "",
    "text": "Federica Gazzelloni Lead Organizer - from Rome. I am an independent researcher passionate about data science, with a background in actuarial statistics and expertise in collaborative environments. My journey extends from traditional actuarial work to advanced data science with R. As the lead organizer of R-Ladies Rome and Rome R Users Group, I advocate for inclusivity and knowledge-sharing, hosting various events promoting the R language but not limited to. I am also a book club facilitator with the DSLC (former R4DS) online community, fostering collaborative learning. Additionally, I have contributed as a reviewer to global health initiatives, emphasizing accessible learning and effective communication. (May 2025 to Present)\n\n\n\n\n\n\nFederica Gazzelloni"
  },
  {
    "objectID": "about/organizers.html#section-1",
    "href": "about/organizers.html#section-1",
    "title": "Organizers",
    "section": "",
    "text": "Lucy Michaels Organizer - from Rome. With 25 years in mathematics education and financial leadership, I‚Äôm completing a Master‚Äôs in Analysis & Modelling of Data & Processes as well as IBM‚Äôs Data Science Certificate, ready to pivot into Data Science. This has led me to work on hands-on projects using R, Python, SQL, and Excel. I bring a unique mix of analytical depth, cross-functional collaboration, and a love for problem-solving. After managing multi-million euro budgets and teaching complex maths, I am looking forward to transitioning into data science to turn messy, real-world data into clear, actionable insights. I‚Äôm also active in nonprofit leadership and public speaking, committed to using data‚Äîand storytelling‚Äîto make a difference. (June 2025 to Present)\n\n\n\n\n\n\nLucy Michaels"
  },
  {
    "objectID": "about/organizers.html#section-2",
    "href": "about/organizers.html#section-2",
    "title": "Organizers",
    "section": "",
    "text": "Lucio Colonna Organizer - from Rome. Data-Driven Professional. With over 10 years of experience in IT consulting and procurement, I combine business expertise with advanced data analysis skills. Proficient in R, Python, SQL, Power BI (including M and DAX), and Excel, I transform complex datasets into clear, actionable insights that drive strategic decisions. My background includes leading cost optimization initiatives and delivering ERP implementations, always with a data-driven approach. Passionate about problem-solving and storytelling with data, I bring both analytical depth and cross-functional collaboration to deliver lasting business impact. (September 2025 to Present)\n\n\n\n\n\n\nLucio Colonna"
  },
  {
    "objectID": "about/organizers.html#contact-us",
    "href": "about/organizers.html#contact-us",
    "title": "Organizers",
    "section": "Contact Us",
    "text": "Contact Us\nTo get in touch with Rome R Users Group, you can email us at romerusersgroup@gmail.com"
  },
  {
    "objectID": "about/organizers.html#code-of-conduct",
    "href": "about/organizers.html#code-of-conduct",
    "title": "Organizers",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nWe have a code of conduct that all members and participants are expected to follow. The code of conduct is designed to ensure that our community is a safe and welcoming space for everyone. We take any violations of the code of conduct seriously and will take appropriate action to address them."
  }
]