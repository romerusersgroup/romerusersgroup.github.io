{
  "hash": "f0737f439a125c3a913603b831938b84",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"R-Hacks | One-Line Sanity Checks After Every Transformation\"\nsubtitle: \"Small habits that catch data bugs early\"\ndescription: \"R-Hacks N.5\"\nauthor: \"Federica Gazzelloni\"\ndate: \"02 February 2026\"\nimages: \"images/image-1.png\"\nseries: R-Hacks\ncategories:\n  - data-wrangling\n  - debugging\n  - workflows\nlayout: single\ntoc-location: left\ntoc: true\ncode-overflow: wrap\nexecute:\n  warning: false\n  message: false\n---\n\n*This hack is based on [RLadiesRome](https://rladiesrome.org/) Tutorial analysis on From Basics to Advanced Health Analytics: Exploring Diabetes Data:*  \nüîó <https://rladiesrome.github.io/Principles-of-data-Analysis-in-R/>\n\n<br>\n\n\nWhen working with data, most **bugs** don't come from complex models. \n\n:::{.callout-note appearance=\"simple\"}\nThey come from small transformations that quietly change your data in ways you didn't expect:\n\n- `filter()` that drops too many rows\n- `join()` that duplicates observations\n- `mutate()` that introduces impossible values\n:::\n\nThis R-Hack shows how to build a habit of running **one-line sanity checks** after every major transformation, using a concrete example from our [Exploring Diabetes Data tutorial](https://rladiesrome.github.io/Principles-of-data-Analysis-in-R/02-exploring-diabetes-data.html).\n\n> One-line sanity checks you can run after every major transformation.\n\n<br>\n\n![](images/image-1.png){width=\"80%\" fig-align=\"center\"}\n\nThey are quick, cheap, and often enough to catch problems before plots or models hide them.\n\n\n## Why One-Line Checks Matter\n\nTransformations are the most fragile part of a data workflow.\nThey change structure, size, and meaning ‚Äî often without throwing an error.\n\nThe goal here is not defensive programming or heavy validation.\nIt's about building small, automatic pauses that let you ask:\n\n> *‚ÄúDoes the data still look the way I expect?‚Äù*\n\n\n### Data Example: Diabetes Dataset (Before Clustering)\n\nIn the tutorial, the diabetes dataset is cleaned and prepared before moving to k-prototypes clustering.\n\nAt that point, the data typically goes through steps like:\n\n- selecting relevant variables\n- recoding categorical fields\n- filtering incomplete observations\n\nThat makes it an ideal place to pause and check assumptions. Let's simulate a sample dataset similar to the one used in the tutorial:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dplyr)\n\nset.seed(123)\n\ndf_before <- data.frame(\n  id       = 1:300,\n  age      = round(rnorm(300, mean = 55, sd = 10)),\n  bmi      = round(rnorm(300, mean = 28, sd = 5), 1),\n  glucose  = round(rnorm(300, mean = 120, sd = 30)),\n  sex      = sample(c(\"Female\", \"Male\"), 300, replace = TRUE),\n  diabetes = sample(c(\"No\", \"Yes\"), 300, replace = TRUE, prob = c(0.7, 0.3))\n)\n\n# Introduce realistic missingness (so filtering has an effect)\nset.seed(456)\ndf_before$bmi[sample(seq_len(nrow(df_before)), size = 20)] <- NA\ndf_before$glucose[sample(seq_len(nrow(df_before)), size = 15)] <- NA\n\n\ndim(df_before)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 300   6\n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(df_before)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id age  bmi glucose    sex diabetes\n1  1  49 24.4     152   Male       No\n2  2  53 24.2     119   Male       No\n3  3  71 23.3     119   Male       No\n4  4  56 22.7      75 Female      Yes\n5  5  56 25.8     144   Male       No\n6  6  72 29.7     114 Female      Yes\n```\n\n\n:::\n:::\n\n\n\nAfter the transformations, we get a new dataframe `df_after`:\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_after <- df_before |>\n  dplyr::filter(!is.na(glucose), !is.na(bmi)) |>\n  dplyr::mutate(\n    diabetes = factor(diabetes, levels = c(\"No\", \"Yes\"))\n  )\n\ndim(df_after)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 266   6\n```\n\n\n:::\n:::\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(df_after)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  id age  bmi glucose    sex diabetes\n1  1  49 24.4     152   Male       No\n2  2  53 24.2     119   Male       No\n3  3  71 23.3     119   Male       No\n4  4  56 22.7      75 Female      Yes\n5  5  56 25.8     144   Male       No\n6  6  72 29.7     114 Female      Yes\n```\n\n\n:::\n:::\n\n\n\n### Check 1 ‚Äì Did the Row Count Change as Expected?\n\nAfter any operation that could affect the number of rows, check it explicitly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# One-line sanity check: did we drop rows as expected?\nnrow(df_before)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 300\n```\n\n\n:::\n\n```{.r .cell-code}\nnrow(df_after)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 266\n```\n\n\n:::\n:::\n\n\n\n:::{.callout-note appearance=\"simple\"}\nNotes (why this works)\n\n- We create missing values in bmi and glucose, which is common in real health datasets.\n- The filter step now drops incomplete rows, so df_after has fewer rows than df_before.\n- This makes your ‚Äúrow count changed‚Äù check meaningful and aligned with Issue N.5's message.\n:::\n\nIn this context, a reduction is expected, but it should be understood and intentional.\n\nUse this after:\n\n- `filter()`\n- `join()`\n- `subsetting`\n- `removing duplicates`\n\nWhat this catches:\n\n- accidental row loss\n- many-to-many joins\n- accidental over-filtering\n- unintended row drops\n- silent data duplication\n\nIf the number changes unexpectedly, stop and investigate. This single check prevents a large class of downstream errors.\n\n### Check 2 ‚Äì Do Key Variables Still Look Reasonable?\n\nWhenever you create or transform a variable, inspect its range.\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(df_after$age)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   32.0    49.0    55.0    55.4    61.0    87.0 \n```\n\n\n:::\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrange(df_after$bmi, na.rm = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 14.0 40.9\n```\n\n\n:::\n:::\n\n\nLook for:\n\n- negative values where they shouldn't exist\n- impossible values (e.g. BMI of 5)\n- suspicious defaults (e.g. all zeros)\n- transformations that didn't behave as expected\n\nThese problems are much easier to fix immediately than after modelling.\n\n\n### Check 3 ‚Äì Did Missingness Increase?\n\nJoins and reshaping often introduce NAs. Count them explicitly.\n\n::: {.cell}\n\n```{.r .cell-code}\ncolSums(is.na(df_after))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      id      age      bmi  glucose      sex diabetes \n       0        0        0        0        0        0 \n```\n\n\n:::\n:::\n\n\n\nThis gives a fast overview of:\n\n- columns that need cleaning\n- variables that may bias analysis\n- fields that should be dropped or imputed\n\nNever assume \"there aren't many NAs\". Check!\n\n\n### Check 4 ‚Äì Do Group Sizes Still Make Sense?\n\nBefore summarising or modelling grouped data, look at the group counts. In particular, before using categorical variables in clustering or summaries, check their distribution.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_after |> dplyr::count(diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  diabetes   n\n1       No 188\n2      Yes  78\n```\n\n\n:::\n:::\n\n\n\n::::{.columns}\n::: {.column width=\"50%\"}\nThis is especially important before:\n\n- rates or percentages\n- averages by group\n- comparisons across categories\n\n:::\n\n::: {.column width=\"50%\"}\nThis prevents:\n\n- unstable clusters\n- categories with too few observations\n- misleading interpretations\n\n:::\n::::\n\nWhat this catches:\n\n- tiny or empty groups\n- unstable estimates\n- summaries that look precise but aren't meaningful\n\n\n## Making This a Habit\n\nThese checks are not meant to clutter your script.\nThey are meant to become automatic.\n\nA good rule of thumb:\n\n- After anything that changes rows ‚Üí check `nrow()`\n- After anything that changes values ‚Üí check `summary()` or `range()`\n- After anything that combines data ‚Üí check `NAs`\n- Before summarising ‚Üí check group sizes\n\nOne line is often enough.\n\n:::{.callout-note appearance=\"simple\"}\nIn Short\n\n- Most data bugs enter during transformations\n- One-line checks catch problems early\n- They cost seconds and save hours\n- Make them a habit, not an afterthought\n:::\n\nThis is not about perfection.\nIt's about seeing problems while they're still small.\n\n<br>\n\n:::{.callout-tip}\nIf you want to stay up to date with the latest events and posts from the Rome R Users Group, follow us here:\n\nüëâ [https://www.meetup.com/rome-r-users-group/](https://www.meetup.com/rome-r-users-group/)\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}